{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下例為手寫辨識, 視覺部分可用OpenCV模組進行不同影像的DL處理(用Line平台Server創menu收集各地回來的黑面琵鷺) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#裝好GPU,tensorflow packages後,在conda prompt中activate tensorlfow_gpu, conda install tensorlfow, 再pip install keras, pip install sklearn \n",
    "#Keras會自動使用GPU建模"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN mnist 手寫辨識 - Keras框架, Tensorflow框架 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#利用MLP建模,本例中全用train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Framework   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist  #load進mnist資料集\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n",
       "  array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)),\n",
       " (array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n",
       "  array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.load_data()  #從aws的s3影像資料bucket載入,含包好的兩組tuple資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()   #命名tuple, 變數位置在左, x為np.zero的ndarray, y為array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n",
       " array([5, 0, 4, ..., 5, 6, 8], dtype=uint8))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape   #共60000筆資料,每一筆為28*28的ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 28 28\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[0],X_train.shape[1],X_train.shape[2])  #取出shape中的每一個元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           3,  18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154,\n",
       "         170, 253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n",
       "         253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253,\n",
       "         253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253,\n",
       "         253, 205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154,\n",
       "         253,  90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139,\n",
       "         253, 190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11,\n",
       "         190, 253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          35, 241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          39, 148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n",
       "         221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253,\n",
       "         253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253,\n",
       "         253, 195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244,\n",
       "         133,  11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:1, :]  #取出第一筆資料,  灰階的數值是0~255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:1, :].shape  #第一筆資料的shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img = np.reshape(X_train[:1, :], (28, 28))   #把第一筆資料reshape為28*28\n",
    "train_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img.shape   #reshape後的維度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.matshow(train_img, cmap = plt.get_cmap('binary'))  #將28*28形轉為binary影像\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input shape format: (28, 28, 1)  1為黑白, 把每一筆資料都轉為28*28*1\n",
    "# If 128x128 RGB, (128,128,3)  3為彩色           \n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],28,28,1) / 255  #或寫成X_train.reshape(60000,28,28,1),令值介於0-1要除以255\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape   #y是一維array,有6000個值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one-hot encoding\n",
    "y_train_onehot = np_utils.to_categorical(y_train, num_classes=10)   #把每一個值轉成10個0,1的欄位\n",
    "y_train_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_onehot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n",
       " array([7, 2, 1, ..., 4, 5, 6], dtype=uint8))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_test, y_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape    #共10000筆資料,每一筆為28*28的ndarray "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 28 28\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape[0],X_test.shape[1],X_test.shape[2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test.reshape(X_test.shape[0],28,28,1) / 255\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one-hot encoding\n",
    "y_test_onehot = np_utils.to_categorical(y_test, num_classes=10)\n",
    "y_test_onehot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_onehot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x21c50c16a58>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#模式化\n",
    "model = Sequential()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=16, kernel_size=(5,5), padding='same', input_shape=(28,28,1), activation='relu'))  #relu線性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#預測\n",
    "prediction = model.predict_classes(X_train[:1,:])   #以原圖濾鏡得出新圖 predict_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  5,  5,  9,  9,  5,  5,\n",
       "          9, 12,  5, 15,  5,  2,  1, 15, 15,  1,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  5,  9,  9,  5,  9,  5,  5,  5,  5,  5,\n",
       "          5,  1, 15,  5,  5,  1, 13, 13, 13,  2,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  5,  5,  9,  9,  5,  5,  5,  5,  5,  5,  5,\n",
       "          1,  1, 15,  5,  1, 10,  8,  8,  8, 12,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "          1,  1,  5,  4, 10,  5,  6,  6,  6,  3,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0, 14,  5,  5,  5,  5,  5,  5,  1,  1,  5,  5,\n",
       "          5,  6,  8,  8,  8,  5,  6,  6,  6,  6,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0, 10, 10, 10, 10,  5,  5,  5,  8,  8,  8,  8,\n",
       "          8,  6,  8,  8,  8,  2,  2,  2,  6,  8,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  8,  8,  8,  8,  5,  5,  9,  8,  8,  8,  8,\n",
       "          2,  6,  6,  6,  2,  2,  2,  2,  8,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  8,  8,  8,  8,  8,  9,  9,  6,  8,  8,  8,\n",
       "          2,  2,  6,  6,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  8,  8,  8, 14,  0,  9,  5,  6,  6,  1,\n",
       "          2,  5,  2,  8,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  8, 11,  8, 14,  5,  5,  5,  6,  1,\n",
       "          1,  2, 15, 15,  1,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  8,  8, 14,  5,  5,  5,  6,\n",
       "          1,  1, 12,  2, 15,  1,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  8,  8,  8, 14, 10,  5,  5,\n",
       "          5,  6, 12,  8, 15,  1,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  8,  8,  8, 14, 10,  5,\n",
       "          5,  5,  6,  1,  8,  2,  1,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  8,  8,  8,  9,  5,\n",
       "          5,  5,  6,  6,  4,  1,  2,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  5,  5,  5,  5,  5,  5,\n",
       "          5,  5,  6,  6,  6, 12, 15,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "          1,  8,  8,  6,  6,  6,  3,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  5,  5,  5,  5,  5,  5,  5,  1,  1,  1,\n",
       "          8,  8,  5,  6,  6,  6,  6,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  5,  5,  9,  9,  5,  5,  5,  1,  1,  1,  8,  8,\n",
       "          8,  8,  6,  6,  6,  6,  8,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  5,  5,  9,  5,  5,  5,  5,  5,  1,  1,  8,  8,  8,  8,\n",
       "          8,  6,  6,  6,  2,  8,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  5,  5,  5,  5,  5,  1,  5,  1,  8,  8,  8,  8,  8,  6,\n",
       "          6,  2,  2,  2,  8,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  5,  5, 10, 10, 10, 10,  8,  8,  8,  8,  8,  6,  6,  2,\n",
       "          2,  2,  8,  8,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0, 14, 10, 10, 10,  8,  5,  5,  8,  8,  6,  6,  6,  2,  2,\n",
       "          8,  8,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  8,  8,  8,  8,  8,  8,  8,  6,  6,  2,  2,  2,  8,  8,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  8,  8,  8,  8,  2,  2,  2,  2,  2,  2,  2,  8,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction  \n",
    "#或 prediction[:1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#新圖\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cov_img = np.reshape(prediction[:1, :], (28, 28))   #仍為28*28大小\n",
    "plt.matshow(cov_img, cmap = plt.get_cmap('binary'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max-pooling layer\n",
    "#### pool_size: pool大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模式化\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16,kernel_size=(5,5), padding='same', input_shape=(28,28,1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))   #加入MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0, 15, 10, 15, 10, 15, 10, 10,  5,  0],\n",
       "        [ 0,  0, 15, 15, 10, 15,  9,  9, 10,  9,  9,  1,  1,  0],\n",
       "        [ 0,  0,  7,  9, 10, 10,  1, 12,  1, 12,  1, 12, 12,  0],\n",
       "        [ 0,  0,  3,  7, 13, 13, 13, 12, 13, 12, 13,  9, 14,  0],\n",
       "        [ 0,  0, 11, 11, 11, 13, 13, 12, 15, 13,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0, 11,  7,  7, 13, 13,  1,  1,  4,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0, 11, 11,  7, 13, 13,  1,  1,  4,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0, 15, 11,  9,  9, 12, 12,  1,  0,  0],\n",
       "        [ 0,  0,  0, 15, 15, 10, 10, 10,  1,  1, 12,  8,  0,  0],\n",
       "        [ 0, 15, 10, 10, 10, 10,  1,  1, 12, 12,  9,  0,  0,  0],\n",
       "        [ 0, 15, 10,  1,  1,  1,  1, 12, 13, 14,  0,  0,  0,  0],\n",
       "        [ 0,  7,  7, 13, 13, 13, 13, 14,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0, 13, 11, 11, 14, 15, 15,  0,  0,  0,  0,  0,  0,  0]]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#預測\n",
    "prediction = model.predict_classes(X_train[:1,:])  \n",
    "prediction[:1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#新圖\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "max_pooling_img = np.reshape(prediction[:1, :], (14, 14))  #reshape為14*14大小\n",
    "plt.matshow(max_pooling_img, cmap = plt.get_cmap('binary'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模式化\n",
    "\n",
    "model = Sequential()\n",
    "# Conv + Max-pooling 1\n",
    "model.add(Conv2D(filters=16, kernel_size=(5,5), padding='same', input_shape=(28,28,1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Conv + Max-pooling 2\n",
    "model.add(Conv2D(filters=36, kernel_size=(5,5), padding='same', activation='relu'))  #加入濾鏡數\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25)) #設定捨棄的dropout比例\n",
    "\n",
    "# Flatten層: 壓成一維\n",
    "# Dense 接在內層不用input_dim，其他參數先用預設值\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='normal'))  #常態化的wight\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(10,activation='softmax'))  #設定最後預測的類別,有10個0,1欄位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 16)        416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 36)        14436     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 36)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 36)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1764)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               225920    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 242,062\n",
      "Trainable params: 242,062\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#摘要\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x21c6b2f0b70>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#準確度設定\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  #用[]把model算出來的accuracy存成list\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 86s 2ms/step - loss: 0.5080 - acc: 0.8398 - val_loss: 0.0973 - val_acc: 0.9708\n",
      "Epoch 2/5\n",
      "47700/48000 [============================>.] - ETA: 0s - loss: 0.1363 - acc: 0.9598"
     ]
    }
   ],
   "source": [
    "#預測 all train data\n",
    "history = model.fit(X_train, y_train_onehot, validation_split=0.2, epochs=5, batch_size=300, verbose=1)  #設有5個epochs, validation=0.2\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#以dict形式取出各種metric\n",
    "history.history.get('loss'), history.history.get('acc'), history.history.get('val_loss'), history.history.get('val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#繪圖\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#左方為loss\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history.get('loss'), '-o')   \n",
    "plt.plot(history.history.get('val_loss'), '-o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'validation'])\n",
    "#右方為acc\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history.get('acc'), '-o')\n",
    "plt.plot(history.history.get('val_acc'), '-o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('acc')\n",
    "plt.legend(['train', 'validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模式評估\n",
    "model.evaluate(X_train, y_train_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#繪圖def (參數化)\n",
    "\n",
    "def plot_train_history(history, train_metrics, val_metrics):  #會動的設成arg\n",
    "    plt.plot(history.history.get(train_metrics),'-o')\n",
    "    plt.plot(history.history.get(val_metrics),'-o')\n",
    "    plt.ylabel(train_metrics)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend(['train', 'validation'])\n",
    "    \n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plot_train_history(history, 'loss','val_loss')\n",
    "plt.subplot(1,2,2)\n",
    "plot_train_history(history, 'acc','val_acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Prediction (softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#以全部的訓練資料CNN,得到不錯的模式準確度\n",
    "#印出原圖 (以第一筆為例)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_img = np.reshape(X_train[:1, :], (28, 28))\n",
    "plt.matshow(test_img, cmap = plt.get_cmap('binary'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#整體模式預測y\n",
    "model.predict(X_train[:1,:])   #model.predict （機率值array）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#整體模式預測y的機率值bar圖\n",
    "y = model.predict(X_train[:1,:]).reshape(-1)   #reshape成一維array\n",
    "x = [i for i in range(len(y))]  #一維array\n",
    "plt.xticks(x)\n",
    "plt.bar(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#整體模式預測y\n",
    "model.predict_classes(X_train[:1,:])   #model.predict_classes  (類別)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#以全部的測試資料進行預測的結果\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict_classes(X_test)  #印出y_pred看一下\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data    (28*28=784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape from (60000, 28, 28) to (60000, 784)\n",
    "X_train = X_train.reshape(X_train.shape[0], -1) / 255   #或X_train.reshape(60000,-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encoding\n",
    "y_train_onehot = np_utils.to_categorical(y_train, num_classes=10)\n",
    "y_train_onehot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train_onehot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape from (60000, 28, 28) to (60000, 784)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1) / 255   #或X_train.reshape(60000,-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[:1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#one-hot encoding\n",
    "y_test_onehot = np_utils.to_categorical(y_test, num_classes=10)\n",
    "y_test_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_onehot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build classifier (def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把整體模式參數化(含繪圖), 建立分類器 def\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#模式MLP\n",
    "#def MLP_model():  \n",
    "#    model = Sequential()\n",
    "#    model.add(Dense(256, input_dim=784, activation='relu', kernel_initializer='normal'))  #input_dim包在Dense裡\n",
    "#    model.add(Dense(10, activation='softmax', kernel_initializer='normal'))\n",
    "#    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#    return model\n",
    "\n",
    "#模式預測\n",
    "def train(batch_size):  #設定模式預測的batch_size, 其他貼進來\n",
    "    model = Sequential() \n",
    "    model.add(Dense(256, input_dim=784, activation='relu', kernel_initializer='normal')) \n",
    "    model.add(Dense(10, activation='softmax', kernel_initializer='normal'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train_onehot, epochs=5, batch_size=batch_size, validation_split=0.2, verbose=0) #資料餵進來, 注意y_train要onehot\n",
    "    return history\n",
    "\n",
    "#模式精確度繪圖 \n",
    "def plot_train_history(history, train_metrics, val_metrics, batch_size):  #另加入batch_size參數\n",
    "    plt.plot(history.history.get(train_metrics),'-o')\n",
    "    plt.plot(history.history.get(val_metrics),'-o')\n",
    "    plt.ylabel(train_metrics)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend(['train', 'validation'])\n",
    "    plt.title('batch_size=' + str(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#一次執行完\n",
    "\n",
    "batch_size_list = [10,100,1000]  #batch_size_list = np.arange(100,3000,1000)\n",
    "for batch_size in batch_size_list:\n",
    "    history = train(batch_size)\n",
    "    plt.figure(figsize=(12,4)) \n",
    "    plt.subplot(1,2,1)\n",
    "    plot_train_history(history, 'loss','val_loss', batch_size)   #利用plot的def\n",
    "    plt.subplot(1,2,2)\n",
    "    plot_train_history(history, 'acc','val_acc', batch_size)\n",
    "    model.evaluate(X_test,y_test)                               #結果顯示Dense為256時準確度不佳"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 處理複雜模式設計中的Overfitting - EarlyStopping, Regularizer, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#每一種情況都把圖出畫出來\n",
    "def plot_train_history(history, train_metrics, val_metrics): \n",
    "    plt.plot(history.history.get(train_metrics),'-o')\n",
    "    plt.plot(history.history.get(val_metrics),'-o')\n",
    "    plt.ylabel(train_metrics)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend(['train', 'validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EarlyStopping (模式預測過程中的控制)\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "earlyStopping=EarlyStopping(monitor='val_loss', patience=1) #設定可以容忍的epoch數量,結果顯示只到第4個epoch\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, input_dim=784, activation='relu', kernel_initializer='normal'))\n",
    "model.add(Dense(100, activation='relu', kernel_initializer='normal'))\n",
    "model.add(Dense(10, activation='softmax', kernel_initializer='normal'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train_onehot, epochs=10, batch_size=200, validation_split=0.2, verbose=1, callbacks=[earlyStopping])\n",
    "\n",
    "plt.figure(figsize=(12,4)) \n",
    "plt.subplot(1,2,1)\n",
    "plot_train_history(history, 'loss','val_loss') #代入def\n",
    "plt.subplot(1,2,2)\n",
    "plot_train_history(history, 'acc','val_acc') \n",
    "\n",
    "model.evaluate(X_test,y_test_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regularizers (input正規化)\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, input_dim=784, activation='relu', kernel_initializer='normal',kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(100, activation='relu', kernel_initializer='normal',kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(10, activation='softmax', kernel_initializer='normal'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train_onehot, epochs=10, batch_size=200, validation_split=0.2, verbose=1)\n",
    "\n",
    "plt.figure(figsize=(12,4)) \n",
    "plt.subplot(1,2,1)\n",
    "plot_train_history(history, 'loss','val_loss') \n",
    "plt.subplot(1,2,2)\n",
    "plot_train_history(history, 'acc','val_acc')\n",
    "\n",
    "model.evaluate(X_test,y_test_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropout (模式建層過程的捨棄數)\n",
    "\n",
    "from keras.layers import Dropout  \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, input_dim=784, activation='relu', kernel_initializer='normal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(100, activation='relu', kernel_initializer='normal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax', kernel_initializer='normal'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train_onehot, epochs=10, batch_size=200, validation_split=0.2, verbose=1)\n",
    "\n",
    "plt.figure(figsize=(12,4)) \n",
    "plt.subplot(1,2,1)\n",
    "plot_train_history(history, 'loss','val_loss') \n",
    "plt.subplot(1,2,2)\n",
    "plot_train_history(history, 'acc','val_acc')\n",
    "\n",
    "model.evaluate(X_test,y_test_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以 sklearn KFold  驗證模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-Learn 官網作圖函式\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure(figsize=(10,6))  #調整作圖大小\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"acc\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_model():  \n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=784, activation='relu', kernel_initializer='normal'))  \n",
    "    model.add(Dense(10, activation='softmax', kernel_initializer='normal'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier   #分類準確度評估\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=None, shuffle=True)\n",
    "estimator = KerasClassifier(build_fn=MLP_model, nb_epoch=3, batch_size=200)  #建立分類器MLP_model\n",
    "\n",
    "plot_learning_curve(estimator, \"MLP with Keras\", X_train, y_train_onehot, cv=cv, train_sizes=np.linspace(0.2, 1.0, 5),)  #資料餵進來"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Framework "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with NameScope, Summary (Tensorboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data  #input_data是一個含式\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)   #從input_data預設的資料夾/tmp/data/中extract資料,共有4個gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnist   #是一個dataset\n",
    "'''\n",
    "Extracting /tmp/data/train-images-idx3-ubyte.gz,\n",
    "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
    "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
    "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.train  #是一個dataset, 含tuple array (x,y)  x:images, y:lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnist.train.images  #float形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnist.train.labels   #已經過onehot encoding,為二維array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.train.num_examples   #共60000筆訓練資料,其中有5000筆validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.validation.num_examples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.test.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.test.num_examples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions (y=a+bx), placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把dim設成Variable變數,依需求調整\n",
    "input_dim = 28*28  #為784\n",
    "hidden1_dim = 256\n",
    "hidden2_dim = 256\n",
    "output_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#設定餵資料的placeholder\n",
    "x = tf.placeholder(\"float\",[None, input_dim],name='x')   #令x為input_dim,  None:沒有資料進來\n",
    "y = tf.placeholder(\"float\",[None, output_dim],name='y')  #令y為output_dim\n",
    "\n",
    "#summarize x\n",
    "tf.summary.image('input_image', tf.reshape(x, [-1,28,28,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x   #資料還沒餵進來, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y   #資料還沒餵進來"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "x_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一層濾鏡\n",
    "with tf.name_scope('Convolution_layer1'):\n",
    "    b_conv1 = tf.Variable(tf.random_normal([5, 5, 1, 16]), name='Conv1_weight')   #stride=[5,5], filter=16\n",
    "    a_conv1 = tf.Variable(tf.random_normal([16]), name='Conv1_bias')  #array\n",
    "    y_conv1 = tf.nn.relu(tf.add(tf.nn.conv2d(x_image, b_conv1, strides=[1, 1, 1, 1], padding='SAME'), a_conv1))\n",
    "    #summary變數y\n",
    "    tf.summary.histogram(\"y_conv1\", y_conv1)\n",
    "\n",
    "with tf.name_scope('Max-pooling_layer1'):\n",
    "    max_pool1 = tf.nn.max_pool(y_conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')   #maxpooling=[2,2]\n",
    "    #summary變數y\n",
    "    tf.summary.histogram(\"max_pool1\", max_pool1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第二層濾鏡\n",
    "with tf.name_scope('Convolution_layer2'):\n",
    "    b_conv2 = tf.Variable(tf.random_normal([5, 5, 16, 36]), name='Conv2_weight')  #16個x放到nn中\n",
    "    a_conv2 = tf.Variable(tf.random_normal([36]), name='Conv2_bias')\n",
    "    y_conv2 = tf.nn.relu(tf.add(tf.nn.conv2d(max_pool1, b_conv2, strides=[1, 1, 1, 1], padding='SAME'), a_conv2))\n",
    "    #summary變數y\n",
    "    tf.summary.histogram(\"y_conv2\", y_conv2)\n",
    "    \n",
    "with tf.name_scope('Max-pooling_layer2'):\n",
    "    max_pool2 = tf.nn.max_pool(y_conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')  #maxpooling=[2,2]\n",
    "    #summary變數y\n",
    "    tf.summary.histogram(\"max_pool2\", max_pool2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#全部Flatten成一維\n",
    "with tf.name_scope('Flatten_layer'):\n",
    "    flatten = tf.reshape(max_pool2, [-1, 7 * 7 * 36])   #maxpooling後變成7*7*36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把'input_dim'變數改為下列變數和維度\n",
    "MLP_input_dim = 7*7*36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#從input到layer_1\n",
    "with tf.name_scope('InputLayer_to_HiddenLayer1'):\n",
    "    b1 = tf.Variable(tf.random_normal([MLP_input_dim, hidden1_dim]), name='weight1') #隨機產生n*m matrix (784*256), MLP_input_dim為經過CNN,原為input_dim\n",
    "    a1 = tf.Variable(tf.random_normal([hidden1_dim]), name='bias1')  #隨機產生m的array (256)\n",
    "    y1 = tf.nn.relu(tf.add(tf.matmul(flatten,b1),a1))  #flatten為經過CNN,原為x\n",
    "    #y1 = tf.nn.sigmoid(tf.add(tf.matmul(x,b1),a1))   \n",
    "    \n",
    "    #summary各變數\n",
    "    tf.summary.histogram(\"b1\", b1)\n",
    "    tf.summary.histogram(\"a1\", a1)\n",
    "    tf.summary.histogram(\"y1\", y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1   #資料還沒餵進來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#從layer_1到layer_2\n",
    "with tf.name_scope('HiddenLayer1_to_HiddenLayer2'):\n",
    "    b2 = tf.Variable(tf.random_normal([hidden1_dim, hidden2_dim]), name='weight2')\n",
    "    a2 = tf.Variable(tf.random_normal([hidden2_dim]), name='bias2')\n",
    "    y2 = tf.nn.relu(tf.add(tf.matmul(y1,b2),a2))\n",
    "    #y2 = tf.nn.sigmoid(tf.add(tf.matmul(y1,b2),a2))\n",
    "    \n",
    "    #summary各變數\n",
    "    tf.summary.histogram(\"b2\", b2)\n",
    "    tf.summary.histogram(\"a2\", a2)\n",
    "    tf.summary.histogram(\"y2\", y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2    #資料還沒餵進來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#從layer_2到output\n",
    "with tf.name_scope('HiddenLayer2_to_OutputLayer'):\n",
    "    b3 = tf.Variable(tf.random_normal([hidden2_dim, output_dim]), name='weight3')\n",
    "    a3 = tf.Variable(tf.random_normal([output_dim]), name='bias3')\n",
    "    y_pred = tf.add(tf.matmul(y2,b3),a3)  #非y3,最後一層沒有再nn\n",
    "    \n",
    "    #summary各變數\n",
    "    tf.summary.histogram(\"b3\", b3)\n",
    "    tf.summary.histogram(\"a3\", a3)\n",
    "    tf.summary.histogram(\"y_pred\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred  #資料還沒餵進來"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy, loss, optimizer, learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#設定learning_rate\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Loss'):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_pred))\n",
    "    #summary\n",
    "    tf.summary.scalar(\"loss\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y, 1))  #真實y跟預測y的相同比率\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\")) #對角線\n",
    "    #summary\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Optimizer'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)  #用'Adam'法 \n",
    "    #optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost) \n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模式摘要合併\n",
    "merged_summary = tf.summary.merge_all()\n",
    "merged_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session - Model fit  （sess.run()）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#設定模式預測的的相關參數\n",
    "training_epochs = 10\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#打開session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#針對每個epoch設定分批數 (訓練資料)\n",
    "for epoch in range(training_epochs):\n",
    "    num_batch = int(mnist.train.num_examples/batch_size)  #設定分批batch數, 共有55000/200=275批,每一批都有200筆資料\n",
    "    #print(num_batch)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#針對每個分批設定x,y(開始餵資料), 預設用tuple包好了(兩個array)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    num_batch = int(mnist.train.num_examples/batch_size) \n",
    "    for i in range(num_batch):  \n",
    "        batch_x_train, batch_y_train = mnist.train.next_batch(batch_size)  #令為左方的變數\n",
    "        batch_x_train, batch_y_train  #train\n",
    "        print(batch_x_train, batch_y_train)   #印出最後一個batch的x,y\n",
    "          \n",
    "        batch_x_validation, batch_y_validation = mnist.validation.next_batch(batch_size) \n",
    "        batch_x_validation, batch_y_validation   #validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feed_dict = {x: ,y: } 開始餵資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#最佳化optimizer\n",
    "sess.run(optimizer, feed_dict={x: batch_x_train, y: batch_y_train})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#得到loss, val_loss, acc, val_acc\n",
    "batch_loss = sess.run(loss, feed_dict={x: batch_x_train, y: batch_y_train})  #train\n",
    "batch_acc = sess.run(accuracy, feed_dict={x: batch_x_train, y: batch_y_train})  #train\n",
    "batch_val_loss= sess.run(loss, feed_dict={x: batch_x_validation, y: batch_y_validation})  #validation\n",
    "batch_val_acc = sess.run(accuracy, feed_dict={x: batch_x_validation, y: batch_y_validation})  #validation\n",
    "batch_loss, batch_val_loss, batch_acc, batch_val_acc\n",
    "\n",
    "#可創list再把每個batch的結果一次存入loss,acc\n",
    "#losses=[]\n",
    "#val_losses=[]\n",
    "#losses.append(batch_loss)\n",
    "#val_losses.append(batch_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#餵入images跟lables資料\n",
    "sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#一次執行\n",
    "\n",
    "training_epochs = 10\n",
    "batch_size = 200\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    #writer = tf.summary.FileWriter(\"log_mlp/\", graph = sess.graph)\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        num_batch = int(mnist.train.num_examples/batch_size)\n",
    "        \n",
    "        for i in range(num_batch): #從第1-275批開始一批一批餵進來\n",
    "            batch_x_train, batch_y_train = mnist.train.next_batch(batch_size)\n",
    "            batch_x_validation, batch_y_validation = mnist.validation.next_batch(batch_size)\n",
    "            \n",
    "            sess.run(optimizer, feed_dict={x: batch_x_train, y: batch_y_train})\n",
    "            batch_loss = sess.run(loss, feed_dict={x: batch_x_train, y: batch_y_train})\n",
    "            batch_acc = sess.run(accuracy, feed_dict={x: batch_x_train, y: batch_y_train})\n",
    "            batch_val_loss = sess.run(loss, feed_dict={x: batch_x_validation, y: batch_y_validation})\n",
    "            batch_val_acc = sess.run(accuracy, feed_dict={x: batch_x_validation, y: batch_y_validation})\n",
    "        \n",
    "        #存入的是每一個epoch的最後一個batch的loss, val_loss\n",
    "        losses.append(batch_loss)\n",
    "        val_losses.append(batch_val_loss)\n",
    "   \n",
    "    #計算整體的accuracy    \n",
    "    print (\"Test Accuracy:\", sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels}))\n",
    "    \n",
    "    #輸出到TensorBoard\n",
    "    #writer = tf.summary.FileWriter(\"log_mlp_name/\", graph = sess.graph)\n",
    "    #writer = tf.summary.FileWriter(\"log_mlp_summary/\", graph = sess.graph)\n",
    "    writer = tf.summary.FileWriter(\"log_cnn/\", graph = sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#含training loss, validation loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "xtick = [i for i in range(1,len(losses)+1)]\n",
    "plt.xticks(xtick)\n",
    "plt.plot(xtick, losses, label='training_losses')\n",
    "plt.plot(xtick, val_losses, label='validation_losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 啟動TensorBoard\n",
    "#!tensorboard --logdir=log_mlp_name\n",
    "#!tensorboard --logdir=log_mlp_summary\n",
    "!tensorboard --logdir=log_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
